{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9a4bf-5b0a-4394-b216-1afeb5417b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /opt/conda/lib/python3.12/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /opt/conda/lib/python3.12/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /opt/conda/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /opt/conda/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.12/site-packages (2.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import ast\n",
    "import contractions\n",
    "import emoji\n",
    "import re\n",
    "import string \n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9b192-bbd1-44fa-a57d-c67e460545b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date&amp;Time</th>\n",
       "      <th>App</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111028</td>\n",
       "      <td>Jasper Ancajas</td>\n",
       "      <td>I have a hard time logging in so i uninstalled...</td>\n",
       "      <td>2020-05-28 19:28:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211245</td>\n",
       "      <td>Tiger 181</td>\n",
       "      <td>im getting no match and like...in stead of spe...</td>\n",
       "      <td>2019-03-03 21:08:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9624</td>\n",
       "      <td>Mr 21</td>\n",
       "      <td>No good</td>\n",
       "      <td>2021-02-03 21:38:00</td>\n",
       "      <td>Hinge</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198692</td>\n",
       "      <td>Tim Stone</td>\n",
       "      <td>got banned for no reason, paid customer for ye...</td>\n",
       "      <td>2019-04-20 13:56:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27599</td>\n",
       "      <td>Thelma Barbara</td>\n",
       "      <td>The more I use this app the more I am appalled...</td>\n",
       "      <td>2021-08-31 17:19:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id            Name                                             Review  \\\n",
       "0  111028  Jasper Ancajas  I have a hard time logging in so i uninstalled...   \n",
       "1  211245       Tiger 181  im getting no match and like...in stead of spe...   \n",
       "2    9624           Mr 21                                            No good   \n",
       "3  198692       Tim Stone  got banned for no reason, paid customer for ye...   \n",
       "4   27599  Thelma Barbara  The more I use this app the more I am appalled...   \n",
       "\n",
       "             Date&Time     App Sentiment  \n",
       "0  2020-05-28 19:28:00  Tinder  negative  \n",
       "1  2019-03-03 21:08:00  Tinder  negative  \n",
       "2  2021-02-03 21:38:00   Hinge  negative  \n",
       "3  2019-04-20 13:56:00  Tinder  negative  \n",
       "4  2021-08-31 17:19:00  Tinder  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Id           50000\n",
       "Name         50000\n",
       "Review       50000\n",
       "Date&Time    50000\n",
       "App          50000\n",
       "Sentiment    50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Id         50000 non-null  int64 \n",
      " 1   Name       50000 non-null  object\n",
      " 2   Review     50000 non-null  object\n",
      " 3   Date&Time  50000 non-null  object\n",
      " 4   App        50000 non-null  object\n",
      " 5   Sentiment  50000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Reload the Data\n",
    "df = pd.read_csv('dataset/cleaned_DatingAppReviewsDataset.csv')\n",
    "\n",
    "df.head()\n",
    "df.count()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05efbf3-9529-4442-9a9f-d6ec674048b9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3831c-1c4e-4888-8888-78607a8f12a6",
   "metadata": {},
   "source": [
    "Preprocessing is a critical first step in any natural language processing (NLP) task. Raw text data is often noisy, containing inconsistent capitalization, unnecessary punctuation, stopwords, emojis, and other irrelevant elements. Without cleaning and standardizing the text, machine learning models struggle to identify meaningful patterns. Effective preprocessing helps by normalizing text, reducing noise, and ensuring that the model focuses only on the content that matters for the specific task â€” in this case, sentiment classification. https://medium.com/@maleeshadesilva21/preprocessing-steps-for-natural-language-processing-nlp-a-beginners-guide-d6d9bf7689c9 \n",
    "\n",
    "For this project, the preprocessing involves several key steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90d106a-ca9c-4200-8702-937d42db605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs: 0\n",
      "Hashtags: 68\n",
      "Non_ASCII_Flag\n",
      "False    49585\n",
      "True       415\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many reviews contain URLs\n",
    "contains_url = df['Review'].str.contains(r'http\\S+', regex=True, na=False)\n",
    "print(f\"URLs: {contains_url.sum()}\")\n",
    "\n",
    "# Count how many reviews contain hashtags\n",
    "contains_hashtag = df['Review'].str.contains(r'#\\w+', regex=True, na=False)\n",
    "print(f\"Hashtags: {contains_hashtag.sum()}\")\n",
    "\n",
    "# Check if a review contains any non-ASCII characters[True]\n",
    "df['Non_ASCII_Flag'] = df['Review'].apply(lambda x: bool(re.search(r'[^\\x00-\\x7F]', str(x))))\n",
    "print(df['Non_ASCII_Flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b79fa4-92c8-4d83-9726-21eff7a58d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date&amp;Time</th>\n",
       "      <th>App</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Non_ASCII_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111028</td>\n",
       "      <td>Jasper Ancajas</td>\n",
       "      <td>I have a hard time logging in so i uninstalled...</td>\n",
       "      <td>2020-05-28 19:28:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211245</td>\n",
       "      <td>Tiger 181</td>\n",
       "      <td>im getting no match and like...in stead of spe...</td>\n",
       "      <td>2019-03-03 21:08:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9624</td>\n",
       "      <td>Mr 21</td>\n",
       "      <td>No good</td>\n",
       "      <td>2021-02-03 21:38:00</td>\n",
       "      <td>Hinge</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198692</td>\n",
       "      <td>Tim Stone</td>\n",
       "      <td>got banned for no reason, paid customer for ye...</td>\n",
       "      <td>2019-04-20 13:56:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27599</td>\n",
       "      <td>Thelma Barbara</td>\n",
       "      <td>The more I use this app the more I am appalled...</td>\n",
       "      <td>2021-08-31 17:19:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id            Name                                             Review  \\\n",
       "0  111028  Jasper Ancajas  I have a hard time logging in so i uninstalled...   \n",
       "1  211245       Tiger 181  im getting no match and like...in stead of spe...   \n",
       "2    9624           Mr 21                                            No good   \n",
       "3  198692       Tim Stone  got banned for no reason, paid customer for ye...   \n",
       "4   27599  Thelma Barbara  The more I use this app the more I am appalled...   \n",
       "\n",
       "             Date&Time     App Sentiment  Non_ASCII_Flag  \n",
       "0  2020-05-28 19:28:00  Tinder  negative           False  \n",
       "1  2019-03-03 21:08:00  Tinder  negative           False  \n",
       "2  2021-02-03 21:38:00   Hinge  negative           False  \n",
       "3  2019-04-20 13:56:00  Tinder  negative           False  \n",
       "4  2021-08-31 17:19:00  Tinder  negative           False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Unwanted Elements, like URLs, hashtags, non-ASCII characters\n",
    "df['Review'] = df['Review'].apply(lambda x: re.sub(r'http\\S+|@\\w+|#\\w+|[^\\x00-\\x7F]+', '', x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5b933-be38-4fc9-9ea3-5037da49687a",
   "metadata": {},
   "source": [
    "Because the reviews are informal, many of them contain contractions like \"can't\", \"it's\", or \"didn't\". Expanding these into their full forms (\"cannot\", \"it is\", \"did not\") helps the model interpret them more accurately. This is especially important for sentiment analysis, since contractions often include negations (like \"not\") that directly influence sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3691e09-cdb2-446b-9e0f-4a4e98951f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions like like can't, it's\n",
    "df['Review'] = df['Review'].apply(contractions.fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd56976-7c98-46b4-b7e6-37fadc5012ca",
   "metadata": {},
   "source": [
    "Lowercasing ensures the model treats words like \"App\" and \"app\" as the same token, removing unnecessary case sensitivity. Tokenization splits each review into individual words (tokens), making further cleaning and feature extraction easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4467e43-c4a6-4b5d-9068-c600d4e343c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date&amp;Time</th>\n",
       "      <th>App</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Non_ASCII_Flag</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111028</td>\n",
       "      <td>Jasper Ancajas</td>\n",
       "      <td>i have a hard time logging in so i uninstalled...</td>\n",
       "      <td>2020-05-28 19:28:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[i, have, a, hard, time, logging, in, so, i, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211245</td>\n",
       "      <td>Tiger 181</td>\n",
       "      <td>i am getting no match and like...in stead of s...</td>\n",
       "      <td>2019-03-03 21:08:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[i, am, getting, no, match, and, like, ..., in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9624</td>\n",
       "      <td>Mr 21</td>\n",
       "      <td>no good</td>\n",
       "      <td>2021-02-03 21:38:00</td>\n",
       "      <td>Hinge</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[no, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198692</td>\n",
       "      <td>Tim Stone</td>\n",
       "      <td>got banned for no reason, paid customer for ye...</td>\n",
       "      <td>2019-04-20 13:56:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[got, banned, for, no, reason, ,, paid, custom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27599</td>\n",
       "      <td>Thelma Barbara</td>\n",
       "      <td>the more i use this app the more i am appalled...</td>\n",
       "      <td>2021-08-31 17:19:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[the, more, i, use, this, app, the, more, i, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id            Name                                             Review  \\\n",
       "0  111028  Jasper Ancajas  i have a hard time logging in so i uninstalled...   \n",
       "1  211245       Tiger 181  i am getting no match and like...in stead of s...   \n",
       "2    9624           Mr 21                                            no good   \n",
       "3  198692       Tim Stone  got banned for no reason, paid customer for ye...   \n",
       "4   27599  Thelma Barbara  the more i use this app the more i am appalled...   \n",
       "\n",
       "             Date&Time     App Sentiment  Non_ASCII_Flag  \\\n",
       "0  2020-05-28 19:28:00  Tinder  negative           False   \n",
       "1  2019-03-03 21:08:00  Tinder  negative           False   \n",
       "2  2021-02-03 21:38:00   Hinge  negative           False   \n",
       "3  2019-04-20 13:56:00  Tinder  negative           False   \n",
       "4  2021-08-31 17:19:00  Tinder  negative           False   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [i, have, a, hard, time, logging, in, so, i, u...  \n",
       "1  [i, am, getting, no, match, and, like, ..., in...  \n",
       "2                                         [no, good]  \n",
       "3  [got, banned, for, no, reason, ,, paid, custom...  \n",
       "4  [the, more, i, use, this, app, the, more, i, a...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization and Lowercasing\n",
    "df['Review'] = df['Review'].astype(str).str.lower()\n",
    "df['Tokens'] = df['Review'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f9d48-d199-419e-96a2-20f4712320a6",
   "metadata": {},
   "source": [
    "Stopwords (like \"the\", \"is\", \"on\") are removed because they carry little meaning. A custom stopword list is used to keep negation words (\"not\", \"no\", \"nor\"), which are helpful to identify negative sentiment. Punctuation and digits are removed to focus purely on textual content. Stripping ensures that no tokens are just empty spaces, which can cause issues during vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feebc429-5305-421c-bd1b-727bb5f2898d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date&amp;Time</th>\n",
       "      <th>App</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Non_ASCII_Flag</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111028</td>\n",
       "      <td>Jasper Ancajas</td>\n",
       "      <td>i have a hard time logging in so i uninstalled...</td>\n",
       "      <td>2020-05-28 19:28:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[hard, time, logging, uninstalled, app, not, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211245</td>\n",
       "      <td>Tiger 181</td>\n",
       "      <td>i am getting no match and like...in stead of s...</td>\n",
       "      <td>2019-03-03 21:08:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[getting, no, match, like, ..., stead, spendin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9624</td>\n",
       "      <td>Mr 21</td>\n",
       "      <td>no good</td>\n",
       "      <td>2021-02-03 21:38:00</td>\n",
       "      <td>Hinge</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[no, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198692</td>\n",
       "      <td>Tim Stone</td>\n",
       "      <td>got banned for no reason, paid customer for ye...</td>\n",
       "      <td>2019-04-20 13:56:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[got, banned, no, reason, paid, customer, year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27599</td>\n",
       "      <td>Thelma Barbara</td>\n",
       "      <td>the more i use this app the more i am appalled...</td>\n",
       "      <td>2021-08-31 17:19:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[use, app, appalled, incredible, number, scamm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id            Name                                             Review  \\\n",
       "0  111028  Jasper Ancajas  i have a hard time logging in so i uninstalled...   \n",
       "1  211245       Tiger 181  i am getting no match and like...in stead of s...   \n",
       "2    9624           Mr 21                                            no good   \n",
       "3  198692       Tim Stone  got banned for no reason, paid customer for ye...   \n",
       "4   27599  Thelma Barbara  the more i use this app the more i am appalled...   \n",
       "\n",
       "             Date&Time     App Sentiment  Non_ASCII_Flag  \\\n",
       "0  2020-05-28 19:28:00  Tinder  negative           False   \n",
       "1  2019-03-03 21:08:00  Tinder  negative           False   \n",
       "2  2021-02-03 21:38:00   Hinge  negative           False   \n",
       "3  2019-04-20 13:56:00  Tinder  negative           False   \n",
       "4  2021-08-31 17:19:00  Tinder  negative           False   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [hard, time, logging, uninstalled, app, not, i...  \n",
       "1  [getting, no, match, like, ..., stead, spendin...  \n",
       "2                                         [no, good]  \n",
       "3  [got, banned, no, reason, paid, customer, year...  \n",
       "4  [use, app, appalled, incredible, number, scamm...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing Stop Words, Punctuation and Digits \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Noticed how some necessary stopwords like 'not' is being removed, so I decided to customize own stopwords \n",
    "custom_stopwords = set(stop_words) - {\"not\", \"no\", \"nor\"}\n",
    "df['Tokens'] = df['Tokens'].apply(lambda tokens: [word for word in tokens if word not in custom_stopwords and word not in string.punctuation and not any (char.isdigit() for char in word)])\n",
    "\n",
    "# Remove Whitespace\n",
    "df['Tokens'] = df['Tokens'].apply(lambda tokens: [token.strip() for token in tokens if token.strip()])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab683ca-600a-48f1-bd89-7ebc904cbd60",
   "metadata": {},
   "source": [
    "To ensure proper normalization of tokens, lemmatization was applied using WordNetLemmatizer, with part-of-speech (POS) tagging to correctly identify verbs, nouns, adjectives, and adverbs. This improves the accuracy of lemmatization, avoiding cases where verbs like 'experiencing' remain unchanged due to being misclassified as nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f055760d-4e37-4c67-b30e-418209735e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date&amp;Time</th>\n",
       "      <th>App</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Non_ASCII_Flag</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111028</td>\n",
       "      <td>Jasper Ancajas</td>\n",
       "      <td>i have a hard time logging in so i uninstalled...</td>\n",
       "      <td>2020-05-28 19:28:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[hard, time, log, uninstalled, app, not, insta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211245</td>\n",
       "      <td>Tiger 181</td>\n",
       "      <td>i am getting no match and like...in stead of s...</td>\n",
       "      <td>2019-03-03 21:08:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[get, no, match, like, ..., stead, spending, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9624</td>\n",
       "      <td>Mr 21</td>\n",
       "      <td>no good</td>\n",
       "      <td>2021-02-03 21:38:00</td>\n",
       "      <td>Hinge</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[no, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198692</td>\n",
       "      <td>Tim Stone</td>\n",
       "      <td>got banned for no reason, paid customer for ye...</td>\n",
       "      <td>2019-04-20 13:56:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[get, ban, no, reason, paid, customer, year, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27599</td>\n",
       "      <td>Thelma Barbara</td>\n",
       "      <td>the more i use this app the more i am appalled...</td>\n",
       "      <td>2021-08-31 17:19:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[use, app, appalled, incredible, number, scammer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id            Name                                             Review  \\\n",
       "0  111028  Jasper Ancajas  i have a hard time logging in so i uninstalled...   \n",
       "1  211245       Tiger 181  i am getting no match and like...in stead of s...   \n",
       "2    9624           Mr 21                                            no good   \n",
       "3  198692       Tim Stone  got banned for no reason, paid customer for ye...   \n",
       "4   27599  Thelma Barbara  the more i use this app the more i am appalled...   \n",
       "\n",
       "             Date&Time     App Sentiment  Non_ASCII_Flag  \\\n",
       "0  2020-05-28 19:28:00  Tinder  negative           False   \n",
       "1  2019-03-03 21:08:00  Tinder  negative           False   \n",
       "2  2021-02-03 21:38:00   Hinge  negative           False   \n",
       "3  2019-04-20 13:56:00  Tinder  negative           False   \n",
       "4  2021-08-31 17:19:00  Tinder  negative           False   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [hard, time, log, uninstalled, app, not, insta...  \n",
       "1  [get, no, match, like, ..., stead, spending, n...  \n",
       "2                                         [no, good]  \n",
       "3  [get, ban, no, reason, paid, customer, year, ....  \n",
       "4  [use, app, appalled, incredible, number, scammer]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization with POS tagging\n",
    "tag_dict = {\n",
    "    \"N\": wordnet.NOUN,\n",
    "    \"V\": wordnet.VERB,\n",
    "    \"J\": wordnet.ADJ,\n",
    "    \"R\": wordnet.ADV\n",
    "}\n",
    "\n",
    "# Return Wordnet POS that WordNetLemmatizer understands\n",
    "def pos_tag_wordnet(text):\n",
    "    tag = nltk.pos_tag([text])[0][1][0].upper()  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)  \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['Tokens'] = df['Tokens'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos_tag_wordnet(token)) for token in tokens]\n",
    ")\n",
    "\n",
    "df.head()\n",
    "\n",
    "# # Lemmatization \n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# df['Tokens'] = df['Tokens'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])\n",
    "# df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1d8dce-c181-491c-ba67-8af8baa5ef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date&amp;Time</th>\n",
       "      <th>App</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111028</td>\n",
       "      <td>Jasper Ancajas</td>\n",
       "      <td>i have a hard time logging in so i uninstalled...</td>\n",
       "      <td>2020-05-28 19:28:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[hard, time, log, uninstalled, app, not, insta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211245</td>\n",
       "      <td>Tiger 181</td>\n",
       "      <td>i am getting no match and like...in stead of s...</td>\n",
       "      <td>2019-03-03 21:08:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[get, no, match, like, ..., stead, spending, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9624</td>\n",
       "      <td>Mr 21</td>\n",
       "      <td>no good</td>\n",
       "      <td>2021-02-03 21:38:00</td>\n",
       "      <td>Hinge</td>\n",
       "      <td>negative</td>\n",
       "      <td>[no, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198692</td>\n",
       "      <td>Tim Stone</td>\n",
       "      <td>got banned for no reason, paid customer for ye...</td>\n",
       "      <td>2019-04-20 13:56:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[get, ban, no, reason, paid, customer, year, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27599</td>\n",
       "      <td>Thelma Barbara</td>\n",
       "      <td>the more i use this app the more i am appalled...</td>\n",
       "      <td>2021-08-31 17:19:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[use, app, appalled, incredible, number, scammer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id            Name                                             Review  \\\n",
       "0  111028  Jasper Ancajas  i have a hard time logging in so i uninstalled...   \n",
       "1  211245       Tiger 181  i am getting no match and like...in stead of s...   \n",
       "2    9624           Mr 21                                            no good   \n",
       "3  198692       Tim Stone  got banned for no reason, paid customer for ye...   \n",
       "4   27599  Thelma Barbara  the more i use this app the more i am appalled...   \n",
       "\n",
       "             Date&Time     App Sentiment  \\\n",
       "0  2020-05-28 19:28:00  Tinder  negative   \n",
       "1  2019-03-03 21:08:00  Tinder  negative   \n",
       "2  2021-02-03 21:38:00   Hinge  negative   \n",
       "3  2019-04-20 13:56:00  Tinder  negative   \n",
       "4  2021-08-31 17:19:00  Tinder  negative   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [hard, time, log, uninstalled, app, not, insta...  \n",
       "1  [get, no, match, like, ..., stead, spending, n...  \n",
       "2                                         [no, good]  \n",
       "3  [get, ban, no, reason, paid, customer, year, ....  \n",
       "4  [use, app, appalled, incredible, number, scammer]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'Non_ASCII_Flag' column\n",
    "df = df.drop('Non_ASCII_Flag', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88e185a-947d-470b-aef7-517761be08dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b9147769df40a39cae53362ed22e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run the polarity score on the entire dataset for EDA\n",
    "sia = SentimentIntensityAnalyzer() \n",
    "res = {}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total = len(df)):\n",
    "    text = row['Review']\n",
    "    myid = row['Id'] \n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd59ee2-9f3e-4822-9e7d-f66b83f3c2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Date&amp;Time</th>\n",
       "      <th>App</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111028</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>Jasper Ancajas</td>\n",
       "      <td>i have a hard time logging in so i uninstalled...</td>\n",
       "      <td>2020-05-28 19:28:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[hard, time, log, uninstalled, app, not, insta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211245</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>Tiger 181</td>\n",
       "      <td>i am getting no match and like...in stead of s...</td>\n",
       "      <td>2019-03-03 21:08:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[get, no, match, like, ..., stead, spending, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9624</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>Mr 21</td>\n",
       "      <td>no good</td>\n",
       "      <td>2021-02-03 21:38:00</td>\n",
       "      <td>Hinge</td>\n",
       "      <td>negative</td>\n",
       "      <td>[no, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198692</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>Tim Stone</td>\n",
       "      <td>got banned for no reason, paid customer for ye...</td>\n",
       "      <td>2019-04-20 13:56:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[get, ban, no, reason, paid, customer, year, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27599</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.5057</td>\n",
       "      <td>Thelma Barbara</td>\n",
       "      <td>the more i use this app the more i am appalled...</td>\n",
       "      <td>2021-08-31 17:19:00</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>negative</td>\n",
       "      <td>[use, app, appalled, incredible, number, scammer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id    neg    neu    pos  compound            Name  \\\n",
       "0  111028  0.074  0.926  0.000   -0.0516  Jasper Ancajas   \n",
       "1  211245  0.167  0.833  0.000   -0.2960       Tiger 181   \n",
       "2    9624  0.431  0.000  0.569    0.1779           Mr 21   \n",
       "3  198692  0.338  0.519  0.143   -0.4588       Tim Stone   \n",
       "4   27599  0.180  0.755  0.065   -0.5057  Thelma Barbara   \n",
       "\n",
       "                                              Review            Date&Time  \\\n",
       "0  i have a hard time logging in so i uninstalled...  2020-05-28 19:28:00   \n",
       "1  i am getting no match and like...in stead of s...  2019-03-03 21:08:00   \n",
       "2                                            no good  2021-02-03 21:38:00   \n",
       "3  got banned for no reason, paid customer for ye...  2019-04-20 13:56:00   \n",
       "4  the more i use this app the more i am appalled...  2021-08-31 17:19:00   \n",
       "\n",
       "      App Sentiment                                             Tokens  \n",
       "0  Tinder  negative  [hard, time, log, uninstalled, app, not, insta...  \n",
       "1  Tinder  negative  [get, no, match, like, ..., stead, spending, n...  \n",
       "2   Hinge  negative                                         [no, good]  \n",
       "3  Tinder  negative  [get, ban, no, reason, paid, customer, year, ....  \n",
       "4  Tinder  negative  [use, app, appalled, incredible, number, scammer]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "\n",
    "vaders = vaders.reset_index().rename(columns={'index':'Id'})\n",
    "\n",
    "vaders = vaders.merge(df, how = 'left')\n",
    "\n",
    "vaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88421843-23a8-4c6a-8ae3-8a9d5e074ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Id         50000 non-null  int64 \n",
      " 1   Name       50000 non-null  object\n",
      " 2   Review     50000 non-null  object\n",
      " 3   Date&Time  50000 non-null  object\n",
      " 4   App        50000 non-null  object\n",
      " 5   Sentiment  50000 non-null  object\n",
      " 6   Tokens     50000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a43c78-f716-4fff-b342-30f06ff810da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE Preprocessed DataFrame to a new CSV file\n",
    "vaders.to_csv('dataset/preprocessed_DatingAppReviewsDataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
